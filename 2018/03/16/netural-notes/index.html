<!DOCTYPE html>
<html>
<head>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="utf-8">

  <!-- PACE Progress Bar START -->
  
    <script src="/js/pace.min.js"></script>
    <link rel="stylesheet" href="https://github.com/HubSpot/pace/raw/master/themes/orange/pace-theme-flash.css">
  
  

  <!-- PACE Progress Bar START -->

  
  <title>netural_notes | KpLearner</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  
    <meta name="keywords" content="安辉,KpLearner,Hui An" />
  
  
  
  
  <meta name="description" content="神经网络学习神经网络和深度学习用神经网络可以进行监督学习。 深度神经网络既有监督学习，又有无监督学习。 神经网络包括：线性回归模型、浅层神经网络、深层神经网络 要点主要有如下几个： 正向传播和反向传播正向传播是指从神经网络输入向输出方向进行 反向传播是指从神经网络输出向输入传递，从而通过梯度下降法得到参数应该要改变的值。 激活函数神经网络必须得有激活函数，而且通常是非线性函数，因为如果是线性函数，">
<meta name="keywords" content="机器学习,笔记">
<meta property="og:type" content="article">
<meta property="og:title" content="netural_notes">
<meta property="og:url" content="https://huianyi.github.io/2018/03/16/netural-notes/index.html">
<meta property="og:site_name" content="KpLearner">
<meta property="og:description" content="神经网络学习神经网络和深度学习用神经网络可以进行监督学习。 深度神经网络既有监督学习，又有无监督学习。 神经网络包括：线性回归模型、浅层神经网络、深层神经网络 要点主要有如下几个： 正向传播和反向传播正向传播是指从神经网络输入向输出方向进行 反向传播是指从神经网络输出向输入传递，从而通过梯度下降法得到参数应该要改变的值。 激活函数神经网络必须得有激活函数，而且通常是非线性函数，因为如果是线性函数，">
<meta property="og:locale" content="zh-CN">
<meta property="og:image" content="https://raw.githubusercontent.com/huianyi/-markdown-png/master/Blog%20Thumbnails/ML%20Notes.jpg">
<meta property="og:updated_time" content="2018-03-19T08:01:47.785Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="netural_notes">
<meta name="twitter:description" content="神经网络学习神经网络和深度学习用神经网络可以进行监督学习。 深度神经网络既有监督学习，又有无监督学习。 神经网络包括：线性回归模型、浅层神经网络、深层神经网络 要点主要有如下几个： 正向传播和反向传播正向传播是指从神经网络输入向输出方向进行 反向传播是指从神经网络输出向输入传递，从而通过梯度下降法得到参数应该要改变的值。 激活函数神经网络必须得有激活函数，而且通常是非线性函数，因为如果是线性函数，">
<meta name="twitter:image" content="https://raw.githubusercontent.com/huianyi/-markdown-png/master/Blog%20Thumbnails/ML%20Notes.jpg">
  
    <link rel="alternate" href="/atom.xml" title="KpLearner" type="application/atom+xml">
  
  <link rel="icon" href="/css/images/favicon.ico">
  
    <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  <link href="https://fonts.googleapis.com/css?family=Open+Sans|Montserrat:700" rel="stylesheet" type="text/css">
  <link href="https://fonts.googleapis.com/css?family=Roboto:400,300,300italic,400italic" rel="stylesheet" type="text/css">
  <link href="//cdn.bootcss.com/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet">
  <style type="text/css">
    @font-face{font-family:futura-pt;src:url(https://use.typekit.net/af/9749f0/00000000000000000001008f/27/l?subset_id=2&fvd=n5) format("woff2");font-weight:500;font-style:normal;}
    @font-face{font-family:futura-pt;src:url(https://use.typekit.net/af/90cf9f/000000000000000000010091/27/l?subset_id=2&fvd=n7) format("woff2");font-weight:500;font-style:normal;}
    @font-face{font-family:futura-pt;src:url(https://use.typekit.net/af/8a5494/000000000000000000013365/27/l?subset_id=2&fvd=n4) format("woff2");font-weight:lighter;font-style:normal;}
    @font-face{font-family:futura-pt;src:url(https://use.typekit.net/af/d337d8/000000000000000000010095/27/l?subset_id=2&fvd=i4) format("woff2");font-weight:400;font-style:italic;}</style>
    
  <link rel="stylesheet" id="athemes-headings-fonts-css" href="//fonts.googleapis.com/css?family=Yanone+Kaffeesatz%3A200%2C300%2C400%2C700&amp;ver=4.6.1" type="text/css" media="all">
  <link rel="stylesheet" href="/css/style.css">

  <script src="/js/jquery-3.1.1.min.js"></script>

  <!-- Bootstrap core CSS -->
  <link rel="stylesheet" href="/css/bootstrap.css" >
  <link rel="stylesheet" href="/css/hiero.css" >
  <link rel="stylesheet" href="/css/glyphs.css" >
  

  <!-- Custom CSS -->
  <link rel="stylesheet" href="/css/my.css">
  <!-- Google Adsense -->
  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
      (adsbygoogle = window.adsbygoogle || []).push({
          google_ad_client: "",
          enable_page_level_ads: true
      });
  </script><!-- hexo-inject:begin --><!-- hexo-inject:end -->
</head>

<script>
var themeMenus = {};

  themeMenus["/"] = "首页"; 

  themeMenus["/archives"] = "归档"; 

  themeMenus["/categories"] = "分类"; 

  themeMenus["/tags"] = "标签"; 

  themeMenus["/about"] = "关于"; 

</script>


  <body data-spy="scroll" data-target="#toc" data-offset="50">


  <!-- hexo-inject:begin --><!-- hexo-inject:end --><header id="allheader" class="site-header" role="banner">
  <div class="clearfix container">
      <div class="site-branding">

          <h1 class="site-title">
            
              <a href="/" title="KpLearner" rel="home"> KpLearner </a>
            
          </h1>

          
            
          <nav id="main-navigation" class="main-navigation" role="navigation">
            <a class="nav-open">Menu</a>
            <a class="nav-close">Close</a>
            <div class="clearfix sf-menu">

              <ul id="main-nav" class="nmenu sf-js-enabled">
                    
                      <li class="menu-item menu-item-type-custom menu-item-object-custom menu-item-home menu-item-1663"> <a class="" href="/">首页</a> </li>
                    
                      <li class="menu-item menu-item-type-custom menu-item-object-custom menu-item-home menu-item-1663"> <a class="" href="/archives">归档</a> </li>
                    
                      <li class="menu-item menu-item-type-custom menu-item-object-custom menu-item-home menu-item-1663"> <a class="" href="/categories">分类</a> </li>
                    
                      <li class="menu-item menu-item-type-custom menu-item-object-custom menu-item-home menu-item-1663"> <a class="" href="/tags">标签</a> </li>
                    
                      <li class="menu-item menu-item-type-custom menu-item-object-custom menu-item-home menu-item-1663"> <a class="" href="/about">关于</a> </li>
                    
              </ul>
            </div>
          </nav>


      </div>
  </div>
</header>


  <div id="originBgDiv" style="background: #fff; width: 100%;">

      <div style="max-height:600px; overflow: hidden;  display: flex; display: -webkit-flex; align-items: center;">
        <img id="originBg" width="100%" alt="" src="">
      </div>

  </div>

  <script>
  function setAboutIMG(){
      var imgUrls = "css/images/pose.jpg,https://source.unsplash.com/collection/954550/1920x1080".split(",");
      var random = Math.floor((Math.random() * imgUrls.length ));
      if (imgUrls[random].startsWith('http') || imgUrls[random].indexOf('://') >= 0) {
        document.getElementById("originBg").src=imgUrls[random];
      } else {
        document.getElementById("originBg").src='/' + imgUrls[random];
      }
  }
  bgDiv=document.getElementById("originBgDiv");
  if(location.pathname.match('about')){
    setAboutIMG();
    bgDiv.style.display='block';
  }else{
    bgDiv.style.display='none';
  }
  </script>



  <div id="container">
    <div id="wrap">
            
      <div id="content" class="outer">
        
          <section id="main" style="float:none;"><article id="post-netural-notes" style="width: 66%; float:left;" class="article article-type-post" itemscope itemprop="blogPost" >
  <div id="articleInner" class="clearfix post-1016 post type-post status-publish format-standard has-post-thumbnail hentry category-template-2 category-uncategorized tag-codex tag-edge-case tag-featured-image tag-image tag-template">
    
<div class="article-gallery">
  <div class="article-gallery-photos">
    
      <a class="article-gallery-img fancybox" href="https://raw.githubusercontent.com/huianyi/-markdown-png/master/Blog%20Thumbnails/ML%20Notes.jpg" rel="gallery_cjexujmeq000j3kgt0ja8479b">
        <img src="https://raw.githubusercontent.com/huianyi/-markdown-png/master/Blog%20Thumbnails/ML%20Notes.jpg" itemprop="image">
      </a>
    
  </div>
</div>

    
      <header class="article-header">
        
  
    <h1 class="thumb" class="article-title" itemprop="name">
      netural_notes
    </h1>
  

      </header>
    
    <div class="article-meta">
      
	Posted on <a href="/2018/03/16/netural-notes/" class="article-date">
	  <time datetime="2018-03-16T02:54:58.000Z" itemprop="datePublished">三月 16, 2018</time>
	</a>

      
	<span id="busuanzi_container_page_pv">
	  本文总阅读量<span id="busuanzi_value_page_pv"></span>次
	</span>

    </div>
    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="神经网络学习"><a href="#神经网络学习" class="headerlink" title="神经网络学习"></a>神经网络学习</h1><h2 id="神经网络和深度学习"><a href="#神经网络和深度学习" class="headerlink" title="神经网络和深度学习"></a>神经网络和深度学习</h2><p>用神经网络可以进行监督学习。</p>
<p>深度神经网络既有监督学习，又有无监督学习。</p>
<p>神经网络包括：线性回归模型、浅层神经网络、深层神经网络</p>
<p>要点主要有如下几个：</p>
<h3 id="正向传播和反向传播"><a href="#正向传播和反向传播" class="headerlink" title="正向传播和反向传播"></a>正向传播和反向传播</h3><p>正向传播是指从神经网络输入向输出方向进行</p>
<p>反向传播是指从神经网络输出向输入传递，从而通过梯度下降法得到参数应该要改变的值。</p>
<h3 id="激活函数"><a href="#激活函数" class="headerlink" title="激活函数"></a>激活函数</h3><p>神经网络必须得有激活函数，而且通常是非线性函数，因为如果是线性函数，会使神经网络的深度并没有任何作用，深度的叠加最后仍旧是线性函数。</p>
<p>常用的激活函数有：</p>
<ul>
<li>sigmoid:$a = \frac{1}{1+e^{-z}}$</li>
<li>tanh:$a = \frac{e^z-e^{-z}}{e^z+e^{-z}}$</li>
<li>Relu:$a=max(0,z)$</li>
<li>lean Relu:$a=max(0.01z,z)$</li>
</ul>
<p><img src="https://www.github.com/huianyi/-markdown-png/blob/master/Deep%20Learning/Activation%20fun%20image.png?raw=true&quot;" alt="activation function images"></p>
<h3 id="损失函数和成本函数"><a href="#损失函数和成本函数" class="headerlink" title="损失函数和成本函数"></a>损失函数和成本函数</h3><p>损失函数(loss function)：用于算法的运行情况，再单个训练样本中的表现<br>线性回归中用的是：</p>
<script type="math/tex; mode=display">L(y,\hat{y}) = -(ylog\hat{y} + (1-y)log(1-\hat{y}))</script><p>成本函数(cost function)：所有训练样本：</p>
<script type="math/tex; mode=display">J(w,b)=\frac{1}{m}\sum_i^m L(y,\hat{y}</script><h3 id="梯度下降法"><a href="#梯度下降法" class="headerlink" title="梯度下降法"></a>梯度下降法</h3><script type="math/tex; mode=display">W = W - \alpha\frac{dJ(w,b)}{dw}</script><script type="math/tex; mode=display">b = b - \alpha\frac{dJ(w,b)}{db}</script><p>其中$\alpha$是学习率，具体来说就是每次迭代的步长，这里最重要的就是偏导数的求导，但根据之前学习的链式求导法则，即可得到结果。</p>
<h3 id="初始化过程"><a href="#初始化过程" class="headerlink" title="初始化过程"></a>初始化过程</h3><p>初始化过程中应当随机初始化权重(w和b，b设为0可以)，其中w不能全部设为0，因为这样会导致帝都下降法失效，另外，w的值一般来说也应该设的小一点，这样才可以有较快的下降速度。(由上边的激活函数就可以知道，w值越大，斜率越小)</p>
<h3 id="超参数和参数"><a href="#超参数和参数" class="headerlink" title="超参数和参数"></a>超参数和参数</h3><p>超参数是指可以对参数(w,b)进行影响的一类人为设定的数字，比如说层数、每层的节点数、学习率等。这些具体后边也会讲到。</p>
<h3 id="Python广播和向量计算加快速度-np-sum-np-dot"><a href="#Python广播和向量计算加快速度-np-sum-np-dot" class="headerlink" title="Python广播和向量计算加快速度(np.sum,np.dot)"></a>Python广播和向量计算加快速度(np.sum,np.dot)</h3><h2 id="改善深层神经网络：超参数调试、正则化以及优化"><a href="#改善深层神经网络：超参数调试、正则化以及优化" class="headerlink" title="改善深层神经网络：超参数调试、正则化以及优化"></a>改善深层神经网络：超参数调试、正则化以及优化</h2><h3 id="偏差和方差"><a href="#偏差和方差" class="headerlink" title="偏差和方差"></a>偏差和方差</h3><p>偏差是相对训练集数据而言，偏差越大说明对数据无法达到很好的拟合效果。</p>
<p>方差则是对于测试集数据而言，方差越大说明该模型对测试数据无法达到很好拟合效果</p>
<div id="flowchart-0" class="flow-chart"></div>

<h3 id="正则化常用方法"><a href="#正则化常用方法" class="headerlink" title="正则化常用方法"></a>正则化常用方法</h3><ol>
<li>L2范式</li>
<li>dropout正则化(常用inverted dropout)：通过对输入端随意归0，从而让当前层尽量不依赖前一层输入来达到。[设置<code>keep-prob</code>变量来控制]</li>
<li>增加训练数据（对图像进行反转、扩大等增加数据）</li>
<li>early stopping：通过绘制训练过程图谱，在方差较小、偏差较小时就停下来，不再进行训练。</li>
</ol>
<h3 id="梯度消失-梯度爆炸"><a href="#梯度消失-梯度爆炸" class="headerlink" title="梯度消失|梯度爆炸"></a>梯度消失|梯度爆炸</h3><p>神经网络的深度不宜过深，因为太深的神经网络会使得激活函数呈指数增长或减少，从而使的网络失效。</p>
<p>解决方案：初始化的时候，根据变量数量(n)随机将部分参数w设置为0：</p>
<p>如$W^{(L)} = np.random.randn(shape)\times np.sqrt(\frac{1}{n^{(L-1)}})$, relu:$\frac{2}{n^{(L-1)}}$</p>
<h3 id="梯度检验"><a href="#梯度检验" class="headerlink" title="梯度检验"></a>梯度检验</h3><p>在程序中，如何检验梯度结果是否正确：</p>
<script type="math/tex; mode=display">\frac{\begin{Vmatrix}d\theta_{approx}-d\theta\end{Vmatrix}_2}{\begin{Vmatrix}d\theta_{approx}\end{Vmatrix}_2+\begin{Vmatrix}d\theta\end{Vmatrix}_2}</script><p>其中$\theta_{approx}$计算就是常用的导数逼近来求得结果</p>
<h3 id="其他梯度下降方法"><a href="#其他梯度下降方法" class="headerlink" title="其他梯度下降方法"></a>其他梯度下降方法</h3><ul>
<li>mini-batch梯度下降法：该梯度下降法常用于数据量大，计算机数量较少时通过划分数据为不同的batch，分别对每个batch进行运算从而最终实现梯度下降（划分一般为$2^n$个，64~512）</li>
<li>momenturn下降法：</li>
</ul>
<script type="math/tex; mode=display">V_{dw} = \beta V_{dw_{-1}}+(1-\beta)dw</script><script type="math/tex; mode=display">w:=w-\alpha V_{dw}</script><p>同理$V_{db}$，该下降法通过指数加权平均使得y轴方向下降幅度较小，而x轴方向下降幅度更大，从而实现加速迭代过程。</p>
<p>注意：指数加权平均在初期可能会存在偏差，常用的修正函数为：$\frac{V_t}{1-\beta^t}$</p>
<ul>
<li>RMSprop：</li>
</ul>
<script type="math/tex; mode=display">S_{dw} = \beta S_{dw_{-1}} + (1-\beta)dw^2</script><script type="math/tex; mode=display">w:=w-\alpha\frac{dw}{\sqrt{S_{dw}}}</script><p>同理b。通过RMSprop可以进一步减少纵轴摆动，因为纵轴摆动较大，假设这里为b，那么db较大，则$S_{db}$较大，因此更新后的b值则较小。</p>
<ul>
<li>Adam：整合momenturn和RMSprop，即</li>
</ul>
<script type="math/tex; mode=display">w:= w-\alpha\frac{V_{dw}}{\sqrt{S_{dw}}}</script><p>可以在分母加一个极小值，从而防止分母为0情况出现。</p>
<h3 id="学习率衰减"><a href="#学习率衰减" class="headerlink" title="学习率衰减"></a>学习率衰减</h3><p>在梯度下降过程中，学习率也应当是减小的，因此这里涉及到学习率的衰减，常用的有：</p>
<script type="math/tex; mode=display">\alpha = \frac{1}{1+decay\_rate\times epoch\_num}\alpha</script><script type="math/tex; mode=display">\alpha = 0.95^{epoch\_num}\alpha</script><h3 id="正则化输入和激活函数输出"><a href="#正则化输入和激活函数输出" class="headerlink" title="正则化输入和激活函数输出"></a>正则化输入和激活函数输出</h3><p>Batch Norm：</p>
<script type="math/tex; mode=display">z_{norm} = \frac{z-u}{\sqrt{\delta^2}}</script><script type="math/tex; mode=display">Z = \gamma z_{norm} + \beta</script><p>通过正则化输入，可以使得分布更加匀称，从而更利于取得更好的结果，另一方面，batch Norm也有很小的dropout的作用。</p>
<p>使用了batch Norm后，则不需要b值，因为通过正则化过程将b值消去。</p>
<p>注意，使用了batch Norm后，在反向传播过程中，$\gamma$、$\beta$也需计算相关梯度</p>
<h3 id="softmax"><a href="#softmax" class="headerlink" title="softmax"></a>softmax</h3><p>softmax与logistic回归不同，logistic通常用于二分分类(即0，1)，而softmax则用于c分类中（即有c种可能结果），其函数如下：</p>
<p>对于任意输入矩阵a来说，输出$\hat{y}$满足：</p>
<script type="math/tex; mode=display">\hat{y}_i = \frac{e^{a_i}}{\sum_i^n e^{a_i}}</script><p>算出来的值即为几种可能情况的概率$P(y|x_i)$</p>
<p>其损失函数为：</p>
<script type="math/tex; mode=display">L(\hat{y},y) = -\sum_{j=1}^n y_ilog\hat{y}_i</script><p>成本函数为各训练数据损失函数之和。<script src="https://cdnjs.cloudflare.com/ajax/libs/raphael/2.2.7/raphael.min.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/flowchart/1.6.5/flowchart.min.js"></script><textarea id="flowchart-0-code" style="display: none">st=>start: Data
op1=>operation: high bias
cond1=>condition: Yes or No?
op2=>operation: Bigger network
op3=>operation: high variant
cond2=>condition: Yes or No?
op4=>operation: more Data|regonization|new network
st->op1->cond1
cond1(yes)->op2->op1
cond1(no)->op3
op3->cond2
cond2(yes)->op4->op2
e=>end
cond2(no)->e</textarea><textarea id="flowchart-0-options" style="display: none">{"scale":1,"line-width":2,"line-length":50,"text-margin":10,"font-size":12}</textarea><script>  var code = document.getElementById("flowchart-0-code").value;  var options = JSON.parse(decodeURIComponent(document.getElementById("flowchart-0-options").value));  var diagram = flowchart.parse(code);  diagram.drawSVG("flowchart-0", options);</script></p>

      
    </div>
    <footer class="entry-meta entry-footer">
      
	<span class="ico-folder"></span>
    <a class="article-category-link" href="/categories/笔记/">笔记</a>

      
  <span class="ico-tags"></span>
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/机器学习/">机器学习</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/笔记/">笔记</a></li></ul>

      
            
      
        
	<section id="comments" class="comment">
	  <div id="disqus_thread">
	  <noscript>Please enable JavaScript to view the <a href="//disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
	  </div>
	</section>

	<script type="text/javascript">
	var disqus_shortname = 'huiblog';
	(function(){
	  var dsq = document.createElement('script');
	  dsq.type = 'text/javascript';
	  dsq.async = true;
	  dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
	  (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
	}());
	(function(){
	  var dsq = document.createElement('script');
	  dsq.type = 'text/javascript';
	  dsq.async = true;
	  dsq.src = '//' + disqus_shortname + '.disqus.com/count.js';
	  (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
	}());
	</script>


      
    </footer>
  </div>
  
    
<nav id="article-nav">
  
    <a href="/2018/03/17/统计学习方法笔记/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption">上一篇</strong>
      <div class="article-nav-title">
        
          统计学习方法笔记
        
      </div>
    </a>
  
  
    <a href="/2018/03/14/AlphaGo Zero - 为何可以工作和如何工作(翻)/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">下一篇</strong>
      <div class="article-nav-title">AlphaGo Zero - 为何可以工作和如何工作(翻)</div>
    </a>
  
</nav>

  
</article>

<!-- Table of Contents -->

  <aside id="sidebar">
    <div id="toc" class="toc-article">
    <strong class="toc-title">文章目录</strong>
    
      <ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#神经网络学习"><span class="nav-number">1.</span> <span class="nav-text">神经网络学习</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#神经网络和深度学习"><span class="nav-number">1.1.</span> <span class="nav-text">神经网络和深度学习</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#正向传播和反向传播"><span class="nav-number">1.1.1.</span> <span class="nav-text">正向传播和反向传播</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#激活函数"><span class="nav-number">1.1.2.</span> <span class="nav-text">激活函数</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#损失函数和成本函数"><span class="nav-number">1.1.3.</span> <span class="nav-text">损失函数和成本函数</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#梯度下降法"><span class="nav-number">1.1.4.</span> <span class="nav-text">梯度下降法</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#初始化过程"><span class="nav-number">1.1.5.</span> <span class="nav-text">初始化过程</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#超参数和参数"><span class="nav-number">1.1.6.</span> <span class="nav-text">超参数和参数</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Python广播和向量计算加快速度-np-sum-np-dot"><span class="nav-number">1.1.7.</span> <span class="nav-text">Python广播和向量计算加快速度(np.sum,np.dot)</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#改善深层神经网络：超参数调试、正则化以及优化"><span class="nav-number">1.2.</span> <span class="nav-text">改善深层神经网络：超参数调试、正则化以及优化</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#偏差和方差"><span class="nav-number">1.2.1.</span> <span class="nav-text">偏差和方差</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#正则化常用方法"><span class="nav-number">1.2.2.</span> <span class="nav-text">正则化常用方法</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#梯度消失-梯度爆炸"><span class="nav-number">1.2.3.</span> <span class="nav-text">梯度消失|梯度爆炸</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#梯度检验"><span class="nav-number">1.2.4.</span> <span class="nav-text">梯度检验</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#其他梯度下降方法"><span class="nav-number">1.2.5.</span> <span class="nav-text">其他梯度下降方法</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#学习率衰减"><span class="nav-number">1.2.6.</span> <span class="nav-text">学习率衰减</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#正则化输入和激活函数输出"><span class="nav-number">1.2.7.</span> <span class="nav-text">正则化输入和激活函数输出</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#softmax"><span class="nav-number">1.2.8.</span> <span class="nav-text">softmax</span></a></li></ol></li></ol></li></ol>
    
    </div>
  </aside>
</section>
        
      </div>
      <footer id="footer" class="site-footer">
  

  <div class="clearfix container">
      <div class="site-info">
	      &copy; 2018 KpLearner All Rights Reserved.
          
            <span id="busuanzi_container_site_uv">
              本站访客数<span id="busuanzi_value_site_uv"></span>人次  
              本站总访问量<span id="busuanzi_value_site_pv"></span>次
            </span>
          
      </div>
      <div class="site-credit">
        Theme by <a href="https://github.com/iTimeTraveler/hexo-theme-hiero" target="_blank">hiero</a>
      </div>
  </div>
</footer>


<!-- min height -->

<script>
    var contentdiv = document.getElementById("content");

    contentdiv.style.minHeight = document.body.offsetHeight - document.getElementById("allheader").offsetHeight - document.getElementById("footer").offsetHeight + "px";
</script>

<!-- Custome JS -->
<script src="/js/my.js"></script>
    </div>
    <!-- <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
    <a href="/categories" class="mobile-nav-link">Categories</a>
  
    <a href="/tags" class="mobile-nav-link">Tags</a>
  
    <a href="/about" class="mobile-nav-link">About</a>
  
</nav> -->
    

<!-- mathjax config similar to math.stackexchange -->

<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [ ['$','$'], ["\\(","\\)"] ],
      processEscapes: true
    }
  });
</script>

<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      tex2jax: {
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
      }
    });
</script>

<script type="text/x-mathjax-config">
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for(i=0; i < all.length; i += 1) {
            all[i].SourceElement().parentNode.className += ' has-jax';
        }
    });
</script>

<script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>


  <link rel="stylesheet" href="/fancybox/jquery.fancybox.css">
  <script src="/fancybox/jquery.fancybox.pack.js"></script>


<script src="/js/scripts.js"></script>
<script src="/js/bootstrap.js"></script>
<script src="/js/main.js"></script>







  <div style="display: none;">
    <script src="https://s95.cnzz.com/z_stat.php?id=1260716016&web_id=1260716016" language="JavaScript"></script>
  </div>



	<script async src="//dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js">
	</script>






  </div>

  <a id="rocket" href="#top" class=""></a>
  <script type="text/javascript" src="/js/totop.js" async=""></script>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [ ["$","$"], ["\\(","\\)"] ],
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
            processEscapes: true
        }
    });
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax();
        for (var i = 0; i < all.length; ++i)
            all[i].SourceElement().parentNode.className += ' has-jax';
    });
</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML"></script><!-- hexo-inject:begin --><!-- hexo-inject:end -->
</body>
</html>
